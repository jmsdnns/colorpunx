{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4edaeeb",
   "metadata": {},
   "source": [
    "# AR Punks\n",
    "Using an Auto Encoder to generate new punks from old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a1c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('/home/tnn1t1s/art/cpunks-10k')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "from matplotlib.colors import rgb2hex\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "import cpunks.cpunks10k as cpunks10k\n",
    "import cpunks.utils as cputils\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"    \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ce8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3765ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = cpunks10k.cpunks10k()\n",
    "(X_train, Y_train), (X_test, Y_test), (labels) = cp.load_data()\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "df = cp.punks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c19ee1e",
   "metadata": {},
   "source": [
    "### meta parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e4aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextManager(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab638c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_loss(y_true, y_pred):\n",
    "            return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "ctx = ContextManager({})\n",
    "ctx.r_loss = r_loss\n",
    "ctx.learning_rate = 0.0005\n",
    "ctx.batch_size = 32\n",
    "ctx.initial_epoch = 0\n",
    "ctx.input_dim = (24, 24, 4)\n",
    "ctx.encoder_conv_filters = [32, 64, 64, 64]\n",
    "ctx.encoder_conv_kernel_size = [3,3,3,3]\n",
    "ctx.encoder_conv_strides = [1,2,2,1]\n",
    "ctx.decoder_conv_t_filters = [64,64,32,4]\n",
    "ctx.decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "ctx.decoder_conv_t_strides = [1,2,2,1]\n",
    "ctx.z_dim = 4\n",
    "ctx.n_layers_encoder = len(ctx.encoder_conv_filters)\n",
    "ctx.n_layers_decoder = len(ctx.decoder_conv_t_filters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2643c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 18:02:51.692298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-30 18:02:51.748948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-30 18:02:51.749211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "370e39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=ctx.input_dim, \n",
    "                      name='encoder_input')\n",
    "\n",
    "x = encoder_input\n",
    "\n",
    "for i in range(ctx.n_layers_encoder):\n",
    "    conv_layer = Conv2D(filters = ctx.encoder_conv_filters[i],\n",
    "                        kernel_size = ctx.encoder_conv_kernel_size[i],\n",
    "                        strides = ctx.encoder_conv_strides[i],\n",
    "                        padding = 'same',\n",
    "                        name = 'encoder_conv_' + str(i))\n",
    "    x = conv_layer(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "x = Flatten()(x)\n",
    "encoder_output= Dense(ctx.z_dim, name='encoder_output')(x)\n",
    "encoder = Model(encoder_input, encoder_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f1616",
   "metadata": {},
   "source": [
    "### The Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3f5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(ctx.z_dim,), name='decoder_input')\n",
    "\n",
    "x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "for i in range(ctx.n_layers_decoder):\n",
    "    conv_t_layer = Conv2DTranspose(filters = ctx.decoder_conv_t_filters[i],\n",
    "                                   kernel_size = ctx.decoder_conv_t_kernel_size[i],\n",
    "                                   strides = ctx.decoder_conv_t_strides[i],\n",
    "                                   padding = 'same',\n",
    "                                   name = 'decoder_conv_t_' + str(i))\n",
    "    x = conv_t_layer(x)\n",
    "    if i < ctx.n_layers_decoder - 1:\n",
    "        x = LeakyReLU()(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(rate = 0.25)(x)\n",
    "    else:\n",
    "        x = Activation('sigmoid')(x)\n",
    "\n",
    "decoder_output = x\n",
    "decoder = Model(decoder_input, decoder_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc310c",
   "metadata": {},
   "source": [
    "### Combine to Build the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9715f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = encoder_input\n",
    "model_output = decoder(encoder_output)\n",
    "\n",
    "model = Model(model_input, model_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f38faa",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77949bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_loss(y_true, y_pred):\n",
    "            return K.mean(K.square(y_true - y_pred), axis = [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f57f32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=ctx.learning_rate)\n",
    "model.compile(optimizer=optimizer, loss = r_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d50a8d",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3273ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40873bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        new_lr = initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "\n",
    "        return new_lr\n",
    "\n",
    "    return LearningRateScheduler(schedule)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdf874ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 18:03:26.367203: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-01-30 18:03:31.304746: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 22s 20ms/step - loss: 0.0527 - lr: 5.0000e-04\n",
      "Epoch 2/200\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.0212 - lr: 5.0000e-04\n",
      "Epoch 3/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0175 - lr: 5.0000e-04\n",
      "Epoch 4/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0159 - lr: 5.0000e-04\n",
      "Epoch 5/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0146 - lr: 5.0000e-04\n",
      "Epoch 6/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0138 - lr: 5.0000e-04\n",
      "Epoch 7/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0132 - lr: 5.0000e-04\n",
      "Epoch 8/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0127 - lr: 5.0000e-04\n",
      "Epoch 9/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0123 - lr: 5.0000e-04\n",
      "Epoch 10/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0120 - lr: 5.0000e-04\n",
      "Epoch 11/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0117 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.0115 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0112 - lr: 5.0000e-04\n",
      "Epoch 14/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0111 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0109 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0108 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0106 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0105 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0104 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0103 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0101 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0100 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0098 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0098 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0096 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.0095 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.0093 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0092 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0090 - lr: 5.0000e-04\n",
      "Epoch 30/200\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.0089 - lr: 5.0000e-04\n",
      "Epoch 31/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0088 - lr: 5.0000e-04\n",
      "Epoch 32/200\n",
      "282/282 [==============================] - 5s 16ms/step - loss: 0.0087 - lr: 5.0000e-04\n",
      "Epoch 33/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0085 - lr: 5.0000e-04\n",
      "Epoch 34/200\n",
      "282/282 [==============================] - 5s 16ms/step - loss: 0.0084 - lr: 5.0000e-04\n",
      "Epoch 35/200\n",
      "282/282 [==============================] - 5s 16ms/step - loss: 0.0083 - lr: 5.0000e-04\n",
      "Epoch 36/200\n",
      "282/282 [==============================] - 5s 16ms/step - loss: 0.0083 - lr: 5.0000e-04\n",
      "Epoch 37/200\n",
      "282/282 [==============================] - 4s 16ms/step - loss: 0.0082 - lr: 5.0000e-04\n",
      "Epoch 38/200\n",
      "282/282 [==============================] - 6s 22ms/step - loss: 0.0082 - lr: 5.0000e-04\n",
      "Epoch 39/200\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 0.0080 - lr: 5.0000e-04\n",
      "Epoch 40/200\n",
      "282/282 [==============================] - 7s 23ms/step - loss: 0.0080 - lr: 5.0000e-04\n",
      "Epoch 41/200\n",
      "282/282 [==============================] - 7s 24ms/step - loss: 0.0079 - lr: 5.0000e-04\n",
      "Epoch 42/200\n",
      "282/282 [==============================] - 6s 23ms/step - loss: 0.0079 - lr: 5.0000e-04\n",
      "Epoch 43/200\n",
      "282/282 [==============================] - 7s 23ms/step - loss: 0.0078 - lr: 5.0000e-04\n",
      "Epoch 44/200\n",
      "282/282 [==============================] - 7s 24ms/step - loss: 0.0077 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "282/282 [==============================] - 7s 23ms/step - loss: 0.0077 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "282/282 [==============================] - 7s 24ms/step - loss: 0.0076 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "282/282 [==============================] - 7s 24ms/step - loss: 0.0076 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "282/282 [==============================] - 7s 24ms/step - loss: 0.0075 - lr: 5.0000e-04\n",
      "Epoch 49/200\n",
      "282/282 [==============================] - 7s 23ms/step - loss: 0.0075 - lr: 5.0000e-04\n",
      "Epoch 50/200\n",
      "282/282 [==============================] - 7s 23ms/step - loss: 0.0074 - lr: 5.0000e-04\n",
      "Epoch 51/200\n",
      "282/282 [==============================] - 7s 24ms/step - loss: 0.0074 - lr: 5.0000e-04\n",
      "Epoch 52/200\n",
      "282/282 [==============================] - 7s 24ms/step - loss: 0.0073 - lr: 5.0000e-04\n",
      "Epoch 53/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0073 - lr: 5.0000e-04\n",
      "Epoch 54/200\n",
      "282/282 [==============================] - 4s 16ms/step - loss: 0.0072 - lr: 5.0000e-04\n",
      "Epoch 55/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0072 - lr: 5.0000e-04\n",
      "Epoch 56/200\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.0072 - lr: 5.0000e-04\n",
      "Epoch 57/200\n",
      "282/282 [==============================] - 6s 21ms/step - loss: 0.0071 - lr: 5.0000e-04\n",
      "Epoch 58/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0071 - lr: 5.0000e-04\n",
      "Epoch 59/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0070 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0070 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0070 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0069 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0069 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0068 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0068 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0067 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0067 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0066 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0066 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0065 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0065 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0065 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0064 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0065 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0064 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0064 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0064 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0063 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0063 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0063 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0063 - lr: 5.0000e-04\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0062 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0062 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0062 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0061 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0061 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0062 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0061 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0061 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0060 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0060 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0060 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0060 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0060 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0060 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0059 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0059 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0059 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0059 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0059 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0057 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0057 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0057 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0057 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0057 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0057 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0057 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0057 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0056 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0056 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0056 - lr: 5.0000e-04\n",
      "Epoch 120/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0056 - lr: 5.0000e-04\n",
      "Epoch 121/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0056 - lr: 5.0000e-04\n",
      "Epoch 122/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0056 - lr: 5.0000e-04\n",
      "Epoch 123/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 124/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0056 - lr: 5.0000e-04\n",
      "Epoch 125/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 126/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 127/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 128/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 129/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 130/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 131/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 132/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 133/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 134/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 135/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0055 - lr: 5.0000e-04\n",
      "Epoch 136/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 137/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 138/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 139/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 140/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 141/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 142/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 143/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 144/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 145/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 146/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0054 - lr: 5.0000e-04\n",
      "Epoch 147/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 148/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 149/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 150/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 151/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 152/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 153/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 154/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 155/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 156/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 157/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 158/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 159/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 160/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0053 - lr: 5.0000e-04\n",
      "Epoch 161/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 163/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 164/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 165/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 166/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 167/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 168/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 169/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 170/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 171/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 172/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 173/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 174/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 175/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 176/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 177/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0052 - lr: 5.0000e-04\n",
      "Epoch 178/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 179/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 180/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 181/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 182/200\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 183/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 184/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 185/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 186/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 187/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 188/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 189/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 190/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 191/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 192/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 193/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 194/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0051 - lr: 5.0000e-04\n",
      "Epoch 195/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 196/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 197/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 198/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 199/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n",
      "Epoch 200/200\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0050 - lr: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55f1cf9a60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "initial_epoch = 0\n",
    "lr_decay = 1\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=ctx.learning_rate,\n",
    "                               decay_factor=lr_decay,\n",
    "                               step_size=1)\n",
    "\n",
    "callbacks_list = [lr_sched]\n",
    "\n",
    "model.fit(X_train,\n",
    "          X_train,\n",
    "          batch_size = ctx.batch_size,\n",
    "          shuffle = True,\n",
    "          epochs = epochs,\n",
    "          initial_epoch = initial_epoch,\n",
    "          callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f326ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x300 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "example_idx = np.random.choice(range(len(X_test)), n_to_show)\n",
    "example_images = X_test[example_idx]\n",
    "\n",
    "z_points = encoder.predict(example_images)\n",
    "\n",
    "reconst_images = decoder.predict(z_points)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = example_images[i]#.squeeze()\n",
    "    ax = fig.add_subplot(2, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=ax.transAxes)   \n",
    "    ax.imshow(img)\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = reconst_images[i]#.squeeze()\n",
    "    ax = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34a677b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.350558  , -13.799404  ,  -2.4654112 ,  -6.299609  ],\n",
       "       [ 10.241212  ,   8.368749  ,   4.796343  ,  -5.5694203 ],\n",
       "       [  0.79132587,   5.842957  ,   7.545964  , -12.111668  ],\n",
       "       [ -1.5601897 ,   3.311593  ,   0.39512634, -18.702225  ],\n",
       "       [  9.647439  ,  -4.27914   ,   5.257742  , -11.377093  ],\n",
       "       [ 12.844572  ,   1.8600631 ,  10.4856    ,  -6.2996225 ],\n",
       "       [ -5.831522  ,  -8.7936535 ,  12.963443  ,  -4.3259063 ],\n",
       "       [ -6.283666  ,  -2.0380917 ,  12.582578  , -15.064583  ],\n",
       "       [-10.365253  , -11.024603  ,  16.105639  ,   3.2864196 ],\n",
       "       [ -9.743848  ,   7.4392285 ,  14.104405  ,   1.9254634 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reconst_images = AE.decoder.predict(z_points)\n",
    "z_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7532d981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5572ed7160>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_s = np.array([[  7.350558  , -13.799404  ,  -2.4654112 ,  -6.299609  ]])\n",
    "reconst_images = decoder.predict(z_s)\n",
    "plt.imshow(reconst_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ebba0",
   "metadata": {},
   "source": [
    "### pick two punks and do the old face morph trick "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "babc995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "punk_x_img = example_images[0]\n",
    "punk_y_img = example_images[8]\n",
    "punk_x_coords = [  7.350558  , -13.799404  ,  -2.4654112 ,  -6.299609  ]\n",
    "punk_y_coords = [-10.365253  , -11.024603  ,  16.105639  ,   3.2864196 ]\n",
    "\n",
    "punk_x_coords = [ 10.241212  ,   8.368749  ,   4.796343  ,  -5.5694203 ]\n",
    "punk_y_coords = [ 12.844572  ,   1.8600631 ,  10.4856    ,  -6.2996225 ]\n",
    "\n",
    "M=20\n",
    "x = punk_x_coords\n",
    "y = punk_y_coords\n",
    "x = zip(np.linspace(x[0],y[0],M),\n",
    "        np.linspace(x[1],y[1],M),\n",
    "        np.linspace(x[2],y[2],M),\n",
    "        np.linspace(x[3],y[3],M),\n",
    "       )\n",
    "z_s = np.array(list(x))\n",
    "#z_s = np.array([[  7.350558  , -13.799404  ,  -2.4654112 ,  -6.299609  ]])\n",
    "reconst_images = decoder.predict(z_s)\n",
    "#plt.imshow(reconst_images[8])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i in range(M):\n",
    "    img = reconst_images[i]#.squeeze()\n",
    "    ax = fig.add_subplot(2, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "98d900da",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_reversed = np.array([reconst_images[i] for i in range(len(reconst_images) - 1, -1, -1)])\n",
    "imgs = np.concatenate((reconst_images, imgs_reversed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "45ea2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "%matplotlib qt\n",
    "\n",
    "imagelist=imgs \n",
    "fig = plt.figure() # make figure\n",
    "\n",
    "# make axesimage object\n",
    "# the vmin and vmax here are very important to get the color map correct\n",
    "im = plt.imshow(imagelist[0]) #, cmap=plt.get_cmap('jet'), vmin=0, vmax=255)\n",
    "\n",
    "# function to update figure\n",
    "def updatefig(j):\n",
    "    # set the data in the axesimage object\n",
    "    im.set_array(imagelist[j])\n",
    "    # return the artists set\n",
    "    return [im]\n",
    "# kick off the animation\n",
    "ani = animation.FuncAnimation(fig, updatefig, frames=range(40), \n",
    "                             interval=48)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "928c4521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[8.64586527e-12, 7.10837611e-10, 1.68376829e-07,\n",
       "          4.89376898e-12],\n",
       "         [4.03700892e-11, 2.29041408e-09, 4.25779461e-07,\n",
       "          1.89102030e-13],\n",
       "         [5.75029954e-12, 9.33254099e-11, 2.21646470e-08,\n",
       "          3.06190147e-18],\n",
       "         ...,\n",
       "         [8.57713511e-10, 1.11316574e-08, 7.32500894e-07,\n",
       "          1.17457122e-09],\n",
       "         [1.10890455e-11, 6.31631483e-11, 4.33741789e-08,\n",
       "          5.85374570e-16],\n",
       "         [1.03824671e-10, 1.99174538e-10, 8.81360762e-10,\n",
       "          2.08911459e-22]],\n",
       "\n",
       "        [[4.78918016e-10, 8.89664165e-09, 2.47082824e-07,\n",
       "          1.84946936e-11],\n",
       "         [1.26472192e-14, 4.90675805e-13, 3.78869575e-11,\n",
       "          6.62591988e-19],\n",
       "         [1.41955675e-13, 4.07707505e-12, 1.90998762e-11,\n",
       "          8.33951516e-17],\n",
       "         ...,\n",
       "         [1.83769579e-12, 1.01226026e-12, 1.23071178e-10,\n",
       "          3.33326357e-13],\n",
       "         [3.92778574e-16, 2.78426109e-16, 9.44868641e-16,\n",
       "          1.64005501e-19],\n",
       "         [2.02744822e-18, 1.25898717e-17, 2.46518269e-18,\n",
       "          1.22406700e-30]],\n",
       "\n",
       "        [[9.15153642e-09, 1.80861747e-07, 5.16986438e-06,\n",
       "          2.03211926e-16],\n",
       "         [2.36566864e-12, 1.57709748e-10, 8.61046345e-09,\n",
       "          5.24773886e-18],\n",
       "         [8.03798972e-11, 2.96555425e-09, 1.28163620e-07,\n",
       "          2.62450787e-15],\n",
       "         ...,\n",
       "         [1.81668898e-22, 6.43286771e-21, 5.71649891e-19,\n",
       "          0.00000000e+00],\n",
       "         [2.03476802e-20, 6.07015507e-20, 1.60311123e-16,\n",
       "          7.78909465e-34],\n",
       "         [6.14038205e-17, 9.81297099e-18, 1.15269770e-15,\n",
       "          2.66145283e-34]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[4.23634652e-14, 1.02781334e-11, 1.32383840e-10,\n",
       "          5.79000700e-16],\n",
       "         [2.34089593e-20, 1.16688946e-17, 1.20659445e-14,\n",
       "          2.41696177e-22],\n",
       "         [5.39091450e-23, 3.12632913e-20, 3.25779832e-18,\n",
       "          2.35489268e-22],\n",
       "         ...,\n",
       "         [4.02660769e-17, 7.35900954e-16, 8.93491976e-17,\n",
       "          1.08034166e-24],\n",
       "         [1.11433378e-16, 2.44074397e-16, 3.58520550e-18,\n",
       "          1.56365988e-15],\n",
       "         [1.41952309e-11, 4.03494821e-10, 4.36306651e-11,\n",
       "          4.74343394e-25]],\n",
       "\n",
       "        [[4.75539219e-10, 5.97807492e-09, 7.82772673e-08,\n",
       "          1.54117949e-16],\n",
       "         [1.55017710e-16, 1.01662826e-14, 8.94752317e-13,\n",
       "          6.70694377e-18],\n",
       "         [4.74301988e-17, 6.29517046e-15, 1.52100554e-13,\n",
       "          1.10989910e-26],\n",
       "         ...,\n",
       "         [4.27824178e-20, 1.96733535e-18, 1.73652590e-17,\n",
       "          3.21132101e-24],\n",
       "         [1.16583378e-19, 5.33361261e-18, 1.47925702e-16,\n",
       "          1.22198585e-23],\n",
       "         [9.55117655e-15, 9.99869404e-14, 4.52180014e-13,\n",
       "          3.71860897e-17]],\n",
       "\n",
       "        [[1.86704856e-08, 1.45933427e-07, 7.03374639e-08,\n",
       "          1.43182524e-18],\n",
       "         [7.69825555e-13, 1.12479366e-11, 1.05550624e-10,\n",
       "          1.07535754e-18],\n",
       "         [3.19791199e-12, 8.57655821e-11, 1.28978717e-10,\n",
       "          1.04466552e-16],\n",
       "         ...,\n",
       "         [1.45487744e-19, 2.43035670e-16, 2.32632808e-16,\n",
       "          5.47790667e-20],\n",
       "         [7.15371416e-16, 9.25925935e-15, 2.20752922e-15,\n",
       "          1.60737224e-17],\n",
       "         [9.94327992e-13, 2.00430406e-12, 3.76947735e-12,\n",
       "          6.00327137e-16]]],\n",
       "\n",
       "\n",
       "       [[[7.29198646e-12, 6.25448249e-10, 1.48189130e-07,\n",
       "          4.14380856e-12],\n",
       "         [3.15119424e-11, 1.89525973e-09, 3.60724925e-07,\n",
       "          1.45491231e-13],\n",
       "         [4.56011964e-12, 7.77505560e-11, 1.88905300e-08,\n",
       "          2.32517244e-18],\n",
       "         ...,\n",
       "         [5.82348392e-10, 8.60458549e-09, 5.83468534e-07,\n",
       "          7.98655420e-10],\n",
       "         [6.97300854e-12, 4.15829905e-11, 3.16318847e-08,\n",
       "          4.46503201e-16],\n",
       "         [7.79560652e-11, 1.53606891e-10, 7.01727176e-10,\n",
       "          1.29476308e-22]],\n",
       "\n",
       "        [[4.16425422e-10, 8.15830425e-09, 2.26717148e-07,\n",
       "          1.43861659e-11],\n",
       "         [1.08417431e-14, 4.44206114e-13, 3.38725055e-11,\n",
       "          4.48005569e-19],\n",
       "         [1.16598856e-13, 3.59367158e-12, 1.59312633e-11,\n",
       "          5.77429904e-17],\n",
       "         ...,\n",
       "         [1.55165063e-12, 9.44799902e-13, 1.13543161e-10,\n",
       "          1.93728646e-13],\n",
       "         [2.58683518e-16, 2.10685589e-16, 7.10113195e-16,\n",
       "          1.41914363e-19],\n",
       "         [1.21524847e-18, 8.28759452e-18, 1.60017066e-18,\n",
       "          5.79422701e-31]],\n",
       "\n",
       "        [[7.33652827e-09, 1.61141543e-07, 4.45591013e-06,\n",
       "          1.25917986e-16],\n",
       "         [1.47941804e-12, 1.15070842e-10, 6.20023988e-09,\n",
       "          2.83159061e-18],\n",
       "         [5.80531491e-11, 2.46795562e-09, 1.02774081e-07,\n",
       "          1.75331500e-15],\n",
       "         ...,\n",
       "         [2.05453825e-22, 7.53942655e-21, 6.05524074e-19,\n",
       "          0.00000000e+00],\n",
       "         [1.78030949e-20, 5.85762070e-20, 1.42926725e-16,\n",
       "          8.57097931e-34],\n",
       "         [4.24529439e-17, 7.67343194e-18, 8.31493175e-16,\n",
       "          1.59209012e-34]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3.52141852e-14, 9.37599824e-12, 1.17545598e-10,\n",
       "          5.45042461e-16],\n",
       "         [1.89840002e-20, 9.89510589e-18, 1.00669095e-14,\n",
       "          2.18906427e-22],\n",
       "         [4.13461911e-23, 2.41915045e-20, 2.55397536e-18,\n",
       "          1.60105291e-22],\n",
       "         ...,\n",
       "         [2.74622210e-17, 4.89460847e-16, 6.19848851e-17,\n",
       "          4.15918186e-25],\n",
       "         [7.41417733e-17, 1.63190731e-16, 2.34807128e-18,\n",
       "          9.61723644e-16],\n",
       "         [1.09275635e-11, 3.19770155e-10, 3.19994552e-11,\n",
       "          2.25534643e-25]],\n",
       "\n",
       "        [[3.73244324e-10, 5.08672304e-09, 6.59583250e-08,\n",
       "          1.18747441e-16],\n",
       "         [1.22826210e-16, 8.65299552e-15, 7.51892201e-13,\n",
       "          6.01300542e-18],\n",
       "         [3.75249525e-17, 5.10993886e-15, 1.21036604e-13,\n",
       "          7.03361248e-27],\n",
       "         ...,\n",
       "         [2.10661075e-20, 1.01890123e-18, 9.30580919e-18,\n",
       "          1.20398594e-24],\n",
       "         [7.29562961e-20, 3.48019327e-18, 1.00313238e-16,\n",
       "          6.02885803e-24],\n",
       "         [6.93105631e-15, 7.27962477e-14, 3.38034098e-13,\n",
       "          2.72527706e-17]],\n",
       "\n",
       "        [[1.55721267e-08, 1.26887372e-07, 6.06274000e-08,\n",
       "          1.07885828e-18],\n",
       "         [6.19480162e-13, 9.33347930e-12, 8.43211612e-11,\n",
       "          7.30749810e-19],\n",
       "         [2.66482496e-12, 7.28938923e-11, 1.07743127e-10,\n",
       "          7.87028339e-17],\n",
       "         ...,\n",
       "         [7.74961347e-20, 1.39619564e-16, 1.40570292e-16,\n",
       "          2.38340833e-20],\n",
       "         [4.65915025e-16, 6.46533684e-15, 1.54748377e-15,\n",
       "          7.92955601e-18],\n",
       "         [7.21986490e-13, 1.46720255e-12, 2.91928916e-12,\n",
       "          3.24682181e-16]]],\n",
       "\n",
       "\n",
       "       [[[6.17689450e-12, 5.52914992e-10, 1.31011518e-07,\n",
       "          3.52075747e-12],\n",
       "         [2.45635335e-11, 1.56748980e-09, 3.06069154e-07,\n",
       "          1.11639911e-13],\n",
       "         [3.61929518e-12, 6.48386067e-11, 1.61418789e-08,\n",
       "          1.77731232e-18],\n",
       "         ...,\n",
       "         [3.98319627e-10, 6.68416522e-09, 4.69552390e-07,\n",
       "          5.70487046e-10],\n",
       "         [4.41962569e-12, 2.75981460e-11, 2.29697346e-08,\n",
       "          3.46080192e-16],\n",
       "         [5.99105834e-11, 1.20058005e-10, 5.63525671e-10,\n",
       "          8.29010328e-23]],\n",
       "\n",
       "        [[3.63575892e-10, 7.50622675e-09, 2.08667700e-07,\n",
       "          1.12560065e-11],\n",
       "         [9.35019596e-15, 4.03839912e-13, 3.04030447e-11,\n",
       "          3.05211577e-19],\n",
       "         [9.55500666e-14, 3.16189718e-12, 1.32871240e-11,\n",
       "          4.01243974e-17],\n",
       "         ...,\n",
       "         [1.27747552e-12, 8.55416757e-13, 1.03842886e-10,\n",
       "          1.06407132e-13],\n",
       "         [1.71231310e-16, 1.60917678e-16, 5.31397978e-16,\n",
       "          1.20076911e-19],\n",
       "         [7.20030118e-19, 5.41105698e-18, 1.02288131e-18,\n",
       "          2.73209620e-31]],\n",
       "\n",
       "        [[5.83224580e-09, 1.42257633e-07, 3.81053405e-06,\n",
       "          7.67384520e-17],\n",
       "         [9.25289576e-13, 8.37970457e-11, 4.46272352e-09,\n",
       "          1.53105806e-18],\n",
       "         [4.18886800e-11, 2.05057815e-09, 8.24097839e-08,\n",
       "          1.16872166e-15],\n",
       "         ...,\n",
       "         [2.40933999e-22, 9.13148104e-21, 6.73388401e-19,\n",
       "          0.00000000e+00],\n",
       "         [1.58278183e-20, 5.72618687e-20, 1.28073737e-16,\n",
       "          9.70804326e-34],\n",
       "         [2.94768260e-17, 6.09103708e-18, 6.03194185e-16,\n",
       "          9.62084844e-35]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.92709785e-14, 8.55306277e-12, 1.04370686e-10,\n",
       "          5.13075808e-16],\n",
       "         [1.53428950e-20, 8.37173533e-18, 8.38677052e-15,\n",
       "          1.98819933e-22],\n",
       "         [3.15630600e-23, 1.86880441e-20, 2.00573204e-18,\n",
       "          1.10428031e-22],\n",
       "         ...,\n",
       "         [1.86855055e-17, 3.21312340e-16, 4.28267303e-17,\n",
       "          1.52741233e-25],\n",
       "         [4.80643982e-17, 1.07595763e-16, 1.52269982e-18,\n",
       "          5.71919081e-16],\n",
       "         [8.35104381e-12, 2.49749860e-10, 2.31998899e-11,\n",
       "          1.10217008e-25]],\n",
       "\n",
       "        [[2.92952773e-10, 4.32824221e-09, 5.55774520e-08,\n",
       "          9.14931638e-17],\n",
       "         [9.72651441e-17, 7.36749596e-15, 6.32519319e-13,\n",
       "          5.39428135e-18],\n",
       "         [2.95636502e-17, 4.14030213e-15, 9.61797983e-14,\n",
       "          4.45882788e-27],\n",
       "         ...,\n",
       "         [1.03393933e-20, 5.20916267e-19, 4.84040328e-18,\n",
       "          4.22593625e-25],\n",
       "         [4.50954539e-20, 2.24132300e-18, 6.67965219e-17,\n",
       "          2.81177656e-24],\n",
       "         [5.02283550e-15, 5.27707828e-14, 2.51655467e-13,\n",
       "          2.04566729e-17]],\n",
       "\n",
       "        [[1.29879156e-08, 1.10327385e-07, 5.22579064e-08,\n",
       "          8.12906112e-19],\n",
       "         [4.98495993e-13, 7.74487332e-12, 6.73619771e-11,\n",
       "          4.96578494e-19],\n",
       "         [2.22060282e-12, 6.19545734e-11, 9.00047328e-11,\n",
       "          5.92932328e-17],\n",
       "         ...,\n",
       "         [3.84131594e-20, 7.39931587e-17, 7.77310423e-17,\n",
       "          8.87948257e-21],\n",
       "         [2.95410046e-16, 4.41249320e-15, 1.07111361e-15,\n",
       "          3.68805011e-18],\n",
       "         [5.21308474e-13, 1.07164451e-12, 2.28423747e-12,\n",
       "          1.72319695e-16]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[6.77328256e-13, 9.66402167e-11, 2.35095552e-08,\n",
       "          1.91170240e-13],\n",
       "         [6.24924971e-13, 8.10551418e-11, 2.92118312e-08,\n",
       "          7.71438327e-16],\n",
       "         [7.92939052e-14, 2.74136725e-12, 1.44880097e-09,\n",
       "          1.83341352e-20],\n",
       "         ...,\n",
       "         [5.49468945e-13, 9.30500815e-11, 1.05259028e-08,\n",
       "          7.98410491e-13],\n",
       "         [1.43456655e-15, 2.38783839e-14, 7.39026826e-11,\n",
       "          3.36394441e-18],\n",
       "         [1.51054635e-12, 3.60897531e-12, 2.33188729e-11,\n",
       "          1.16061198e-25]],\n",
       "\n",
       "        [[6.51805901e-11, 2.53395216e-09, 7.49348388e-08,\n",
       "          3.85301898e-13],\n",
       "         [1.62416355e-15, 1.12982818e-13, 8.49962375e-12,\n",
       "          1.19135061e-21],\n",
       "         [2.07443049e-15, 1.72068712e-13, 4.97739708e-13,\n",
       "          2.99804052e-20],\n",
       "         ...,\n",
       "         [2.22811864e-14, 1.31930410e-13, 1.96344364e-11,\n",
       "          7.74025211e-19],\n",
       "         [1.69390485e-19, 2.17390675e-18, 5.14841721e-18,\n",
       "          2.20908943e-21],\n",
       "         [2.20489551e-22, 8.83141239e-21, 1.03768455e-21,\n",
       "          5.47942909e-36]],\n",
       "\n",
       "        [[4.17499091e-10, 3.62440069e-08, 5.92351682e-07,\n",
       "          9.65504210e-20],\n",
       "         [2.14333577e-15, 1.52961194e-12, 8.40687173e-11,\n",
       "          6.67729130e-22],\n",
       "         [3.97091621e-13, 1.25100139e-10, 4.23907354e-09,\n",
       "          8.24917343e-19],\n",
       "         ...,\n",
       "         [1.48284666e-21, 1.60994796e-19, 3.07737017e-18,\n",
       "          0.00000000e+00],\n",
       "         [1.20340925e-21, 2.47543298e-20, 1.37226468e-17,\n",
       "          1.49967659e-32],\n",
       "         [3.13932129e-19, 4.98079103e-19, 1.13043164e-17,\n",
       "          1.74089239e-37]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.94470739e-15, 2.29029274e-12, 1.62551188e-11,\n",
       "          2.41356956e-16],\n",
       "         [4.68633713e-22, 4.79846594e-19, 4.38452047e-16,\n",
       "          9.95433032e-23],\n",
       "         [1.13753476e-24, 5.83854056e-22, 8.40965577e-20,\n",
       "          1.93596445e-24],\n",
       "         ...,\n",
       "         [1.43604190e-19, 1.09481159e-18, 2.89726782e-19,\n",
       "          3.06470914e-31],\n",
       "         [1.92077891e-19, 3.40833826e-19, 4.44793514e-21,\n",
       "          2.30922626e-18],\n",
       "         [1.30734304e-13, 5.06784111e-12, 2.27572572e-13,\n",
       "          4.97662291e-30]],\n",
       "\n",
       "        [[6.87849343e-12, 3.16276283e-10, 3.06680170e-09,\n",
       "          9.99056750e-19],\n",
       "         [1.94762219e-18, 3.86487052e-16, 2.88276720e-14,\n",
       "          2.50331452e-19],\n",
       "         [7.09776283e-19, 1.32157892e-16, 2.21749689e-15,\n",
       "          1.27829754e-30],\n",
       "         ...,\n",
       "         [4.46295050e-25, 4.28560204e-23, 3.52763602e-22,\n",
       "          3.51711248e-31],\n",
       "         [2.54613803e-23, 2.42105123e-21, 1.25974967e-19,\n",
       "          1.08660113e-28],\n",
       "         [1.80828614e-17, 2.30700091e-16, 1.88170677e-15,\n",
       "          3.06963029e-19]],\n",
       "\n",
       "        [[7.43930528e-10, 1.31641444e-08, 4.99862329e-09,\n",
       "          4.55551749e-21],\n",
       "         [1.10180216e-14, 3.06996751e-13, 1.47099661e-12,\n",
       "          1.02989994e-21],\n",
       "         [7.07545052e-14, 2.77817678e-12, 2.72149707e-12,\n",
       "          2.79283058e-19],\n",
       "         ...,\n",
       "         [1.04244793e-24, 6.58494211e-21, 8.60116941e-21,\n",
       "          3.84468850e-27],\n",
       "         [3.47173209e-19, 1.59787190e-17, 4.18035244e-18,\n",
       "          6.61199356e-23],\n",
       "         [4.48391205e-15, 1.23006387e-14, 5.98060216e-14,\n",
       "          1.31055160e-20]]],\n",
       "\n",
       "\n",
       "       [[[5.66116761e-13, 8.33504030e-11, 2.06041957e-08,\n",
       "          1.50088438e-13],\n",
       "         [4.84088681e-13, 6.57532362e-11, 2.51460808e-08,\n",
       "          5.47336385e-16],\n",
       "         [5.79638876e-14, 2.10553059e-12, 1.21506627e-09,\n",
       "          1.25098070e-20],\n",
       "         ...,\n",
       "         [2.98786142e-13, 6.07415576e-11, 7.17429138e-09,\n",
       "          3.99179957e-13],\n",
       "         [7.62866830e-16, 1.38302167e-14, 4.74988694e-11,\n",
       "          1.86105877e-18],\n",
       "         [1.15388948e-12, 2.82752467e-12, 1.87823975e-11,\n",
       "          6.71933600e-26]],\n",
       "\n",
       "        [[5.79052951e-11, 2.33868214e-09, 6.95475819e-08,\n",
       "          2.95871780e-13],\n",
       "         [1.36842927e-15, 9.77999284e-14, 7.44912378e-12,\n",
       "          7.97546907e-22],\n",
       "         [1.59184437e-15, 1.38559940e-13, 3.95868044e-13,\n",
       "          1.90582300e-20],\n",
       "         ...,\n",
       "         [1.56215508e-14, 1.11797805e-13, 1.72441800e-11,\n",
       "          2.76934227e-19],\n",
       "         [9.62969742e-20, 1.53056176e-18, 3.86513211e-18,\n",
       "          1.14153580e-21],\n",
       "         [1.22773843e-22, 5.59274705e-21, 6.53638585e-22,\n",
       "          2.53531456e-36]],\n",
       "\n",
       "        [[3.62105929e-10, 3.37989192e-08, 5.31675312e-07,\n",
       "          6.55927278e-20],\n",
       "         [1.51134818e-15, 1.21493234e-12, 6.67862779e-11,\n",
       "          4.36027227e-22],\n",
       "         [2.96064280e-13, 1.02986640e-10, 3.40916140e-09,\n",
       "          5.32944042e-19],\n",
       "         ...,\n",
       "         [1.50136795e-21, 1.82056986e-19, 3.30471145e-18,\n",
       "          0.00000000e+00],\n",
       "         [9.97204700e-22, 2.28494282e-20, 1.20956503e-17,\n",
       "          1.73803672e-32],\n",
       "         [2.11039210e-19, 3.98900923e-19, 8.43321222e-18,\n",
       "          1.09247728e-37]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.57412126e-15, 2.03561452e-12, 1.39581307e-11,\n",
       "          2.27560510e-16],\n",
       "         [3.51267695e-22, 3.77340589e-19, 3.42575805e-16,\n",
       "          8.85795691e-23],\n",
       "         [8.81187608e-25, 4.51956411e-22, 6.53636828e-20,\n",
       "          1.33901497e-24],\n",
       "         ...,\n",
       "         [1.09407212e-19, 7.61841926e-19, 2.12047918e-19,\n",
       "          1.32860508e-31],\n",
       "         [1.33938106e-19, 2.28336694e-19, 3.02098800e-21,\n",
       "          1.65221293e-18],\n",
       "         [9.48066766e-14, 3.74483257e-12, 1.65251358e-13,\n",
       "          2.35736383e-30]],\n",
       "\n",
       "        [[5.42672244e-12, 2.68672723e-10, 2.53159449e-09,\n",
       "          7.63704168e-19],\n",
       "         [1.45038976e-18, 3.08111993e-16, 2.26127744e-14,\n",
       "          1.97385172e-19],\n",
       "         [5.24431371e-19, 1.00736212e-16, 1.62145209e-15,\n",
       "          6.64362136e-31],\n",
       "         ...,\n",
       "         [2.28627101e-25, 2.26219054e-23, 1.87883822e-22,\n",
       "          1.45142613e-31],\n",
       "         [1.51567774e-23, 1.49085522e-21, 8.25326112e-20,\n",
       "          5.37664451e-29],\n",
       "         [1.21045591e-17, 1.57434864e-16, 1.35368920e-15,\n",
       "          2.14334775e-19]],\n",
       "\n",
       "        [[6.09425788e-10, 1.13389840e-08, 4.22775326e-09,\n",
       "          3.09739840e-21],\n",
       "         [8.47760803e-15, 2.46131295e-13, 1.12670409e-12,\n",
       "          6.82930492e-22],\n",
       "         [5.41092372e-14, 2.18814441e-12, 2.07335386e-12,\n",
       "          1.90062569e-19],\n",
       "         ...,\n",
       "         [5.23873899e-25, 3.52810868e-21, 4.71114659e-21,\n",
       "          1.50594645e-27],\n",
       "         [2.21493067e-19, 1.09606576e-17, 2.86181186e-18,\n",
       "          3.00440137e-23],\n",
       "         [3.19106470e-15, 9.02113043e-15, 4.62228861e-14,\n",
       "          6.34885798e-21]]],\n",
       "\n",
       "\n",
       "       [[[4.72053820e-13, 7.17450266e-11, 1.80354078e-08,\n",
       "          1.17527028e-13],\n",
       "         [3.74716724e-13, 5.32771396e-11, 2.16153868e-08,\n",
       "          3.87213091e-16],\n",
       "         [4.26323371e-14, 1.62142684e-12, 1.02094067e-09,\n",
       "          8.53996693e-21],\n",
       "         ...,\n",
       "         [1.61575777e-13, 3.92367736e-11, 4.79574558e-09,\n",
       "          1.95438487e-13],\n",
       "         [4.06051369e-16, 7.98194976e-15, 3.02616474e-11,\n",
       "          1.01199458e-18],\n",
       "         [8.69653579e-13, 2.19039110e-12, 1.49702629e-11,\n",
       "          3.87765441e-26]],\n",
       "\n",
       "        [[5.13467706e-11, 2.15496354e-09, 6.44648210e-08,\n",
       "          2.27035418e-13],\n",
       "         [1.14981684e-15, 8.43787930e-14, 6.50980615e-12,\n",
       "          5.31355804e-22],\n",
       "         [1.22146894e-15, 1.11211238e-13, 3.13923502e-13,\n",
       "          1.21351467e-20],\n",
       "         ...,\n",
       "         [1.10515717e-14, 9.60053096e-14, 1.51588950e-11,\n",
       "          1.03753122e-19],\n",
       "         [5.54886714e-20, 1.08805839e-18, 2.89060188e-18,\n",
       "          6.12319742e-22],\n",
       "         [6.73826431e-23, 3.47821047e-21, 4.02770366e-22,\n",
       "          1.18967495e-36]],\n",
       "\n",
       "        [[3.13874288e-10, 3.15202833e-08, 4.77154174e-07,\n",
       "          4.44951599e-20],\n",
       "         [1.06633549e-15, 9.64923996e-13, 5.30518234e-11,\n",
       "          2.85598218e-22],\n",
       "         [2.20398068e-13, 8.45145412e-11, 2.73104317e-09,\n",
       "          3.42970149e-19],\n",
       "         ...,\n",
       "         [1.50470474e-21, 2.07277309e-19, 3.61015575e-18,\n",
       "          0.00000000e+00],\n",
       "         [8.19049413e-22, 2.11970977e-20, 1.05399974e-17,\n",
       "          2.20930460e-32],\n",
       "         [1.39777083e-19, 3.15740837e-19, 6.18931772e-18,\n",
       "          7.32727420e-38]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.26961324e-15, 1.81203316e-12, 1.20041902e-11,\n",
       "          2.11729755e-16],\n",
       "         [2.62447813e-22, 2.97542579e-19, 2.67726071e-16,\n",
       "          7.99041818e-23],\n",
       "         [6.74054526e-25, 3.49079660e-22, 5.04839055e-20,\n",
       "          9.14948882e-25],\n",
       "         ...,\n",
       "         [8.24945222e-20, 5.29693015e-19, 1.55865423e-19,\n",
       "          5.76360456e-32],\n",
       "         [9.40544229e-20, 1.53593003e-19, 2.06589549e-21,\n",
       "          1.13997100e-18],\n",
       "         [6.72653190e-14, 2.71127478e-12, 1.18886766e-13,\n",
       "          1.07825106e-30]],\n",
       "\n",
       "        [[4.29334953e-12, 2.29274280e-10, 2.09363216e-09,\n",
       "          5.90252872e-19],\n",
       "         [1.07755443e-18, 2.45954942e-16, 1.77046098e-14,\n",
       "          1.54546316e-19],\n",
       "         [3.83998463e-19, 7.65741144e-17, 1.18054656e-15,\n",
       "          3.47181669e-31],\n",
       "         ...,\n",
       "         [1.15935522e-25, 1.19295940e-23, 9.90682701e-23,\n",
       "          6.05926783e-32],\n",
       "         [8.98211542e-24, 9.16372029e-22, 5.40830718e-20,\n",
       "          2.70453738e-29],\n",
       "         [8.08240575e-18, 1.06336960e-16, 9.61235753e-16,\n",
       "          1.52684022e-19]],\n",
       "\n",
       "        [[4.99099873e-10, 9.75568604e-09, 3.57138741e-09,\n",
       "          2.10518758e-21],\n",
       "         [6.53329302e-15, 1.97498742e-13, 8.63322163e-13,\n",
       "          4.53836096e-22],\n",
       "         [4.14811381e-14, 1.72721830e-12, 1.58465819e-12,\n",
       "          1.30596581e-19],\n",
       "         ...,\n",
       "         [2.63193358e-25, 1.89127213e-21, 2.55843732e-21,\n",
       "          5.94516615e-28],\n",
       "         [1.44451403e-19, 7.63491924e-18, 1.98609601e-18,\n",
       "          1.36219460e-23],\n",
       "         [2.29368179e-15, 6.62777913e-15, 3.59516968e-14,\n",
       "          2.98567853e-21]]]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fliplr(imagelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "227f1b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50.        ,  50.22951001,  51.65954843,  53.54784071,\n",
       "        54.16080199,  52.62690164,  51.33685056,  51.96529875,\n",
       "        53.81171398,  53.46036084,  51.97383462,  50.42967686,\n",
       "        51.2597444 ,  50.35699308,  50.99130769,  50.73309503,\n",
       "        50.37042526,  50.51658112,  50.68231661,  50.81549758,\n",
       "        50.15148978,  51.0301716 ,  50.13155094,  50.15137389,\n",
       "        51.58692929,  52.48626729,  50.64413343,  50.07071077,\n",
       "        50.23037206,  51.31181615,  52.18496392,  52.89935137,\n",
       "        52.61700356,  52.00899919,  50.21616944,  51.74719467,\n",
       "        52.50753001,  50.67923493,  52.290616  ,  51.09142722,\n",
       "        53.04009299,  53.49699457,  51.60103674,  52.40731132,\n",
       "        54.12604298,  55.66700451,  54.55200258,  56.46347237,\n",
       "        57.75534135,  57.1542537 ,  58.31410262,  59.38042541,\n",
       "        60.16157668,  61.74301148,  62.79063647,  62.27384778,\n",
       "        62.30159501,  61.00634676,  62.1390522 ,  63.37709705,\n",
       "        63.8369324 ,  65.27531457,  66.064945  ,  66.38351722,\n",
       "        67.39541615,  66.05576715,  65.94144699,  67.44566215,\n",
       "        66.6041671 ,  65.92068381,  66.76113278,  65.19228492,\n",
       "        66.51333632,  66.4560321 ,  68.21152736,  67.02819163,\n",
       "        67.10161001,  67.83231366,  66.36343143,  66.7273358 ,\n",
       "        65.48228989,  64.93211063,  65.1765357 ,  66.83374145,\n",
       "        65.07985652,  64.57362073,  63.16263642,  63.80476698,\n",
       "        64.36375029,  62.66207243,  61.23917959,  62.24894821,\n",
       "        64.15844416,  65.4523812 ,  64.6838073 ,  64.09262772,\n",
       "        65.04160729,  65.04246004,  66.81343411,  67.39739407,\n",
       "        66.15660767,  67.83986566,  67.35804891,  66.00352678,\n",
       "        67.74692457,  69.48458712,  71.42917279,  73.09258058,\n",
       "        71.25829878,  70.45664033,  71.47700416,  73.48079214,\n",
       "        74.03259406,  73.87660532,  74.75554166,  73.07479563,\n",
       "        71.26175683,  71.54069828,  70.1391396 ,  70.73095188,\n",
       "        71.74896236,  73.50236865,  74.10807112,  74.59007728,\n",
       "        76.64356282,  76.12253841,  74.37147701,  72.65355869,\n",
       "        70.95683828,  73.02531343,  72.90667847,  72.75501548,\n",
       "        73.40524236,  74.58299614,  73.45766521,  74.8377682 ,\n",
       "        75.87165405,  75.03727205,  76.06071702,  75.78158756,\n",
       "        74.44724207,  74.91183219,  76.93091583,  76.39739489,\n",
       "        77.40922848,  75.67481797,  74.31231773,  73.57720442,\n",
       "        71.87789789,  70.13856833,  70.89653697,  70.20783225,\n",
       "        71.09655677,  70.76731666,  72.10187087,  73.38729901,\n",
       "        71.7814533 ,  72.43925258,  73.26909105,  74.36987893,\n",
       "        75.85794354,  77.76566046,  76.80390198,  76.81646206,\n",
       "        75.00092583,  73.63910597,  73.45826949,  73.05539666,\n",
       "        72.63791075,  71.65097849,  70.62802187,  71.12254848,\n",
       "        70.39396309,  69.70073606,  71.28366858,  70.28956386,\n",
       "        68.94412105,  68.3760819 ,  69.04399351,  67.14177926,\n",
       "        69.09713734,  68.13153199,  67.94891326,  67.29622552,\n",
       "        68.87332149,  68.88748649,  69.65887792,  67.9973139 ,\n",
       "        66.60407744,  64.93665782,  65.00555751,  64.5705755 ,\n",
       "        64.04995912,  62.70894234,  62.51576999,  63.84816348,\n",
       "        62.75951352,  64.71602224,  65.51362861,  65.49826841,\n",
       "        66.53047485,  64.85340493,  63.49921698,  65.13106061,\n",
       "        64.00627268,  65.76911928,  67.03734741,  67.60482848,\n",
       "        69.47994027,  67.97876339,  69.17043494,  68.56199821,\n",
       "        67.3876004 ,  69.31087509,  67.54887925,  67.76139884,\n",
       "        68.68513185,  67.93391738,  69.48130697,  68.85502606,\n",
       "        67.92105613,  66.51541682,  67.96933008,  67.12646458,\n",
       "        65.75946475,  65.60092441,  63.81494783,  65.86929662,\n",
       "        65.28782941,  65.63151862,  65.83607648,  64.96121967,\n",
       "        64.57925831,  65.50008047,  65.59291081,  64.16314785,\n",
       "        64.6183765 ,  65.78629713,  66.77067499,  68.4557577 ,\n",
       "        69.96654303,  71.53941532,  71.10930332,  72.80653271,\n",
       "        73.8446963 ,  72.18758991,  73.25686221,  71.6060513 ,\n",
       "        73.13618165,  73.91704893,  74.86349228,  74.62724182,\n",
       "        76.13499797,  76.49482198,  75.38179166,  75.55749071,\n",
       "        74.44645591,  72.97210297,  74.42696001,  75.99193618,\n",
       "        76.40626748,  77.59069426,  78.31462194,  76.94013843,\n",
       "        78.78847056,  77.79385925,  78.06397689,  79.94640743,\n",
       "        78.83965316,  79.76647988,  81.14663139,  83.03417716,\n",
       "        82.87003393,  83.52552453,  82.07362601,  82.0311816 ,\n",
       "        83.26545372,  81.49145283,  83.07720569,  81.73155209,\n",
       "        80.70206559,  81.52542158,  82.85116925,  82.62932476,\n",
       "        82.86841869,  83.38634519,  83.60078312,  83.70293131,\n",
       "        83.49416294,  84.93173969,  84.09201602,  83.73732348,\n",
       "        84.65916373,  85.17258223,  87.20561498,  88.7454007 ,\n",
       "        88.38059045,  87.12896283,  88.67381955,  90.25874917,\n",
       "        90.16754698,  90.59426681,  90.83344426,  91.59072291,\n",
       "        90.78607614,  91.30108634,  89.50184607,  87.61156963,\n",
       "        88.62271958,  90.44064061,  89.89047008,  88.21920798,\n",
       "        90.09153429,  91.37751714,  89.75278335,  88.67558247,\n",
       "        87.33690761,  88.33600928,  88.30817088,  87.40484126,\n",
       "        87.22735371,  88.04229498,  87.42981489,  87.11411036,\n",
       "        86.41365309,  87.01184183,  87.14348911,  85.73991787,\n",
       "        86.6979096 ,  86.28915614,  86.11079357,  86.85034657,\n",
       "        85.58236586,  85.95512917,  86.56656785,  86.53255483,\n",
       "        86.17557758,  85.7757963 ,  87.29991202,  86.57234751,\n",
       "        85.40718867,  85.28777348,  86.4606406 ,  86.10835917,\n",
       "        86.60574847,  86.14758425,  84.97237317,  85.15595492,\n",
       "        84.88247404,  85.0836409 ,  84.24663549,  82.78973996,\n",
       "        82.81380034,  84.81730443,  85.65896982,  87.26018063,\n",
       "        85.85838615,  86.33250589,  87.88979996,  88.27251523,\n",
       "        87.66107953,  87.95459288,  87.31032421,  87.41362374,\n",
       "        88.67633744,  90.127388  ,  89.83072743,  88.11389804,\n",
       "        88.02500772,  86.75977372,  86.33636602,  86.54908399,\n",
       "        86.79056879,  85.2074107 ,  83.59449057,  83.551898  ,\n",
       "        83.52081586,  84.04858129,  82.32916987,  81.47932643,\n",
       "        80.66933529,  79.46099514,  80.86686432,  81.22205262,\n",
       "        79.38721896,  80.91097579,  81.08909273,  82.10265981,\n",
       "        82.65594414,  82.39346812,  84.33179442,  82.85409712,\n",
       "        83.71768094,  82.05639564,  83.80181057,  83.46744327,\n",
       "        81.83156632,  80.60618001,  80.42978637,  79.36738912,\n",
       "        78.09380015,  78.92882913,  78.20307642,  77.50405677,\n",
       "        75.7014045 ,  76.75332112,  75.24085889,  75.8499756 ,\n",
       "        76.78470148,  78.48679559,  80.18476495,  79.80465557,\n",
       "        80.61683979,  81.85861989,  83.88634057,  82.33200769,\n",
       "        84.10105389,  84.07073753,  84.18512633,  86.05162237,\n",
       "        86.54001604,  87.14017284,  88.68497301,  87.65925977,\n",
       "        87.4465194 ,  85.86289837,  85.56253424,  83.69350078,\n",
       "        82.69174912,  84.03701172,  85.28582948,  84.0919272 ,\n",
       "        82.22381248,  81.64805401,  82.40944567,  83.30213715,\n",
       "        83.24164649,  83.79456474,  85.24453024,  85.75388185,\n",
       "        87.18891851,  86.81854987,  88.42882522,  88.06956749,\n",
       "        87.93803165,  86.07897426,  87.64702689,  88.58409508,\n",
       "        87.82165902,  87.80838381,  88.53586136,  87.18946415,\n",
       "        85.6496697 ,  85.32430171,  85.23218877,  84.56303242,\n",
       "        82.77115846,  82.58809231,  83.79205546,  84.9298605 ,\n",
       "        83.75036908,  84.06899003,  84.63430622,  84.54892746,\n",
       "        83.75431516,  84.05300545,  85.6233591 ,  86.82575747,\n",
       "        88.85819766,  90.77240145,  92.78848692,  92.9926589 ,\n",
       "        94.09285425,  93.3989692 ,  93.94969817,  93.02787869,\n",
       "        93.81567082,  93.19114651,  94.19915586,  93.54243905,\n",
       "        92.28070789,  93.01909078,  91.25809502,  91.42240489,\n",
       "        90.02129951,  91.55968033,  91.39272228,  92.79620169,\n",
       "        92.39353178,  90.55880021,  90.22629725,  90.94933863,\n",
       "        89.3202383 ,  90.21501136,  90.49806972,  91.20844561,\n",
       "        91.33909628,  91.43691326,  90.50496011,  91.9109786 ,\n",
       "        90.23636364,  88.6076205 ,  87.18413948,  87.14038614,\n",
       "        88.22845126,  88.94784507,  87.84357894,  88.78208718,\n",
       "        90.55699864,  89.51602512,  89.58987632,  88.83728656,\n",
       "        90.65847331,  90.84319237,  92.00779605,  92.22913308,\n",
       "        93.49401118,  91.65080728,  91.9603476 ,  90.33571144,\n",
       "        89.41736352,  90.31566928,  89.16475178,  89.67120259,\n",
       "        88.70749047,  87.44160256,  87.53293528,  86.51241621,\n",
       "        84.79835793,  86.0867129 ,  87.62053548,  85.78595218,\n",
       "        87.61462924,  86.19016075,  87.56728734,  89.59432871,\n",
       "        88.12542692,  88.75006492,  90.00699544,  88.85179126,\n",
       "        88.83971685,  88.17779305,  90.01867764,  88.83803002,\n",
       "        87.52765453,  87.28857921,  87.39148104,  86.56395853,\n",
       "        85.70486992,  84.60782066,  82.75060109,  81.16384291,\n",
       "        80.51058312,  80.01933795,  78.65874931,  79.49665688,\n",
       "        77.59639418,  77.95367942,  79.86882357,  79.72893103,\n",
       "        79.55243245,  79.19390133,  79.22288457,  78.10237099,\n",
       "        76.40628964,  76.41167133,  76.70325426,  75.73881134,\n",
       "        75.92044189,  75.48707761,  73.61854984,  73.89260171,\n",
       "        73.76726222,  72.7767356 ,  73.69316374,  74.45767968,\n",
       "        76.21657688,  75.18115568,  75.85891089,  74.47095905,\n",
       "        75.99048964,  76.34587321,  77.65969169,  77.81358768,\n",
       "        77.23512095,  79.10428309,  77.50161075,  78.0644331 ,\n",
       "        77.368152  ,  77.5963014 ,  76.30801647,  74.7890608 ,\n",
       "        72.88066026,  73.01958389,  73.20400302,  73.83636551,\n",
       "        74.24742584,  72.45005346,  73.27156393,  75.09048824,\n",
       "        73.55395094,  74.33077841,  72.99270525,  71.74069485,\n",
       "        70.97941943,  69.87551872,  70.97024228,  72.07903171,\n",
       "        70.29586665,  69.23819743,  70.17693539,  72.1105212 ,\n",
       "        71.70751715,  70.0182305 ,  71.48110234,  71.64385714,\n",
       "        71.56553263,  71.99530693,  73.783049  ,  74.01464603,\n",
       "        74.1692665 ,  73.24919024,  73.6830886 ,  72.13535371,\n",
       "        72.42733715,  70.98175959,  70.01737052,  71.14309137,\n",
       "        71.254587  ,  71.17326204,  71.06174242,  71.20747085,\n",
       "        69.83304627,  69.9244843 ,  70.22699292,  70.00408393,\n",
       "        71.45851997,  71.16682276,  69.50937199,  69.07725089,\n",
       "        68.89033644,  70.4565579 ,  69.83453905,  68.69669235,\n",
       "        68.39643105,  70.06574041,  71.02742745,  72.93878134,\n",
       "        71.88591261,  72.56491785,  72.81070863,  73.58556153,\n",
       "        74.77224571,  72.94385612,  74.24770317,  74.74139433,\n",
       "        74.45176382,  73.11169134,  71.82819714,  72.81197539,\n",
       "        71.91324217,  72.02267747,  72.87509635,  71.12084203,\n",
       "        69.32437817,  69.52898822,  70.35555165,  69.70017059,\n",
       "        70.24339933,  71.86990781,  70.77781774,  71.27372942,\n",
       "        70.79735891,  72.73224321,  74.6291114 ,  76.13266345,\n",
       "        75.43772565,  74.69988232,  74.45791362,  73.65725603,\n",
       "        75.47825715,  74.75075614,  76.51287607,  78.09661126,\n",
       "        78.59836025,  78.42185176,  77.99822301,  76.35295796,\n",
       "        74.91758786,  73.43122132,  75.4285261 ,  77.38670526,\n",
       "        77.07006329,  77.643575  ,  76.75529962,  77.03648367,\n",
       "        77.19624575,  76.68555989,  75.46151864,  75.51478739,\n",
       "        73.84996465,  74.26206609,  76.29005321,  77.93671743,\n",
       "        77.35548347,  79.2824637 ,  78.3895769 ,  77.59896425,\n",
       "        76.0846334 ,  75.89361415,  75.81615344,  76.17881339,\n",
       "        77.03943297,  75.41075304,  76.18738333,  77.59328104,\n",
       "        77.92592188,  78.10362155,  78.60289674,  76.76625127,\n",
       "        77.73712933,  77.7395328 ,  78.90543364,  79.9295354 ,\n",
       "        80.47253682,  82.20278471,  81.46818025,  83.30296931,\n",
       "        85.19211427,  84.67190107,  85.06040515,  86.68368342,\n",
       "        88.1867425 ,  88.75200458,  87.52043967,  88.15984857,\n",
       "        87.5159348 ,  87.28996392,  87.47039781,  86.28102656,\n",
       "        85.62901272,  86.52960874,  85.77142279,  86.14709761,\n",
       "        86.01300635,  88.03989964,  87.75318715,  88.03601364,\n",
       "        90.05787743,  90.98546225,  90.66009197,  92.22565869,\n",
       "        94.10513543,  94.6166859 ,  94.81886632,  93.10254316,\n",
       "        92.14921614,  92.49359943,  94.22292974,  92.4638758 ,\n",
       "        92.47837919,  92.70896739,  93.42144056,  93.5069042 ,\n",
       "        93.201438  ,  91.55146965,  92.96204309,  94.85277988,\n",
       "        92.97061201,  91.07864092,  90.23578515,  90.30818572,\n",
       "        89.35891126,  88.99650229,  90.95940696,  91.2527376 ,\n",
       "        92.27249671,  93.07835688,  91.33507905,  91.3281881 ,\n",
       "        90.70914754,  89.55209562,  90.65268665,  89.80261374,\n",
       "        89.3658031 ,  89.33318747,  90.25829201,  88.82266018,\n",
       "        86.98280984,  86.9883321 ,  85.36328596,  85.43106787,\n",
       "        86.2743124 ,  87.41578792,  86.4738644 ,  84.80151402,\n",
       "        86.72707349,  85.01652964,  86.73084614,  86.1316609 ,\n",
       "        87.40034276,  88.46444169,  88.58811434,  88.37330568,\n",
       "        90.1870861 ,  89.43484915,  90.52943322,  92.47354086,\n",
       "        91.08478997,  89.44270751,  88.81865797,  89.7790544 ,\n",
       "        89.91662259,  89.34043327,  87.85242159,  86.70346782,\n",
       "        87.70898156,  86.60751544,  87.36223329,  87.76014004,\n",
       "        88.84024218,  89.69813302,  89.90110702,  91.87639024,\n",
       "        91.47166682,  92.40815328,  93.56445846,  92.16960691,\n",
       "        91.77650945,  90.42685727,  89.47653131,  89.03739123,\n",
       "        90.2555873 ,  91.72823891,  90.32406457,  89.12150072,\n",
       "        88.50665275,  89.92809031,  89.67934331,  90.37175325,\n",
       "        89.05450864,  89.49944207,  90.82102961,  90.0892152 ,\n",
       "        90.4144553 ,  89.01971131,  88.8668641 ,  90.34682172,\n",
       "        89.9026463 ,  88.78758983,  88.06546555,  89.45796358,\n",
       "        88.49110607,  88.02044957,  86.36356728,  85.45006813,\n",
       "        84.90976893,  83.15267422,  82.29121857,  82.20056706,\n",
       "        82.05063438,  82.14885421,  81.58151929,  83.4884625 ,\n",
       "        84.69803162,  84.55055234,  85.96550158,  87.02672907,\n",
       "        88.33490421,  87.9199363 ,  89.36551407,  90.3933886 ,\n",
       "        90.28764756,  89.39311329,  87.62774281,  89.65300583,\n",
       "        90.08753773,  90.23576223,  88.56433581,  87.94064966,\n",
       "        89.29333588,  89.15618886,  90.60681524,  89.66127455,\n",
       "        88.04479163,  86.58486245,  87.4302622 ,  86.25905505,\n",
       "        85.26703484,  84.14276531,  82.65971902,  82.61392939,\n",
       "        80.91899319,  80.01307176,  79.2013818 ,  80.24573154,\n",
       "        82.1913091 ,  80.97593198,  82.11585631,  81.41613648,\n",
       "        80.62285027,  80.64995349,  78.83024083,  79.40230841,\n",
       "        77.94328943,  78.84228628,  77.42567095,  76.63917155,\n",
       "        75.67078262,  74.7358925 ,  75.17732223,  74.21512185,\n",
       "        73.60974304,  72.73153705,  74.65749365,  72.98540415,\n",
       "        72.2714036 ,  73.38588046,  75.07059238,  73.59572471,\n",
       "        75.15819969,  76.08395796,  75.88531631,  77.77026233,\n",
       "        77.05760954,  77.49530781,  77.28139031,  77.40241484,\n",
       "        77.72330503,  79.4845852 ,  79.80701371,  80.70921993,\n",
       "        80.81673314,  80.39196923,  80.71424454,  79.87528281,\n",
       "        81.15440816,  79.83765991,  81.65448809,  81.87269861,\n",
       "        83.39620307,  85.16595384,  83.34810212,  85.32292856,\n",
       "        84.85086896,  83.38863395,  82.67865787,  82.53604357,\n",
       "        80.94269734,  82.37891564,  83.81687682,  82.10935403,\n",
       "        83.07533929,  83.85011814,  85.77000534,  84.00600387,\n",
       "        82.78494846,  82.84285726,  83.47618914,  85.14641222,\n",
       "        86.23312493,  87.77439258,  89.12978546,  90.69816912,\n",
       "        89.1770637 ,  90.4595881 ,  92.04408731,  93.49858345,\n",
       "        93.82537906,  93.54419874,  92.80041606,  91.42849641,\n",
       "        90.85078352,  92.06833639,  91.02611282,  92.39404124,\n",
       "        93.82012829,  95.27629773,  94.04458398,  95.78625705,\n",
       "        97.10015061,  97.68347486,  98.22584912,  98.51039292,\n",
       "        97.35142389,  95.77194311,  95.63537651,  94.52286516,\n",
       "        95.3240569 ,  97.21377222,  96.94050111,  98.21338017,\n",
       "        97.49798232,  96.08805794,  94.93560665,  95.39079153,\n",
       "        95.93797983,  97.47341481,  99.32806215, 100.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bounded_random_walk(length, lower_bound,  upper_bound, start, end, std):\n",
    "    assert (lower_bound <= start and lower_bound <= end)\n",
    "    assert (start <= upper_bound and end <= upper_bound)\n",
    "\n",
    "    bounds = upper_bound - lower_bound\n",
    "\n",
    "    rand = (std * (np.random.random(length) - 0.5)).cumsum()\n",
    "    rand_trend = np.linspace(rand[0], rand[-1], length)\n",
    "    rand_deltas = (rand - rand_trend)\n",
    "    rand_deltas /= np.max([1, (rand_deltas.max()-rand_deltas.min())/bounds])\n",
    "\n",
    "    trend_line = np.linspace(start, end, length)\n",
    "    upper_bound_delta = upper_bound - trend_line\n",
    "    lower_bound_delta = lower_bound - trend_line\n",
    "\n",
    "    upper_slips_mask = (rand_deltas-upper_bound_delta) >= 0\n",
    "    upper_deltas =  rand_deltas - upper_bound_delta\n",
    "    rand_deltas[upper_slips_mask] = (upper_bound_delta - upper_deltas)[upper_slips_mask]\n",
    "\n",
    "    lower_slips_mask = (lower_bound_delta-rand_deltas) >= 0\n",
    "    lower_deltas =  lower_bound_delta - rand_deltas\n",
    "    rand_deltas[lower_slips_mask] = (lower_bound_delta + lower_deltas)[lower_slips_mask]\n",
    "\n",
    "    return trend_line + rand_deltas\n",
    "\n",
    "randomData = bounded_random_walk(1000, lower_bound=50, upper_bound =100, start=50, end=100, std=10)\n",
    "randomData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584920fc",
   "metadata": {},
   "source": [
    "## Reducing Dimensions and staying true to the colorpunx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd278e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(mnist_x_train, mnist_y_train), (mnist_x_test, minst_y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c17fd3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.uint8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist_x_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9a57cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70bf40",
   "metadata": {},
   "source": [
    "Training the AR on the (24,24,4) sized input gave some interesting results, specifically, we saw that the pixel colors mutated into a blend of the mostlikely colors. but, these are n'/t actualy cryptopunks. we can greatly simmply the model by limting the colors tot he 2222 colrso used in CPACV-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16068a50",
   "metadata": {},
   "source": [
    "map every X_train[0] to (24,24, 1) where the color channel is uint8 and maps to a colormap that can be used to reconstruct later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "da061750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class CryptoPunksColorMap:\n",
    "    def __init__(self):\n",
    "        with open(f\"../data/_colors_count.pickle\", 'rb') as f:\n",
    "            self.colors_count = pickle.load(f)\n",
    "            self.colors = list(self.colors_count.keys())\n",
    "            self.color_d = {}\n",
    "            i=0\n",
    "            for k in self.colors:\n",
    "                self.color_d[k] = i\n",
    "                i+=1\n",
    "    \n",
    "    def flatten(self, img):\n",
    "        return np.array([[self.colors_d[str(c)] for c in row]\n",
    "                                    for row in img]).astype(np.uint8)\n",
    "    \n",
    "    def unflatten(self,img):\n",
    "        return np.array([[np.fromstring(self.colors[c][1:-1], float, sep=' ') for c in row]\n",
    "                                                                       for row in img])\n",
    "\n",
    "cpm = CryptoPunksColorMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc8091",
   "metadata": {},
   "source": [
    "### Prepare a new Training Set with lower dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67cff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_flat = [cpm.flatten(img) for img in X_train]\n",
    "#X_test_flat  = [cpm.flatten(img) for img in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d154328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle them so we can restore progress\n",
    "with open(f\"../data/_x_train_flat.pickle\", 'wb') as filehandler:\n",
    "    pickle.dump(X_train_flat, filehandler)\n",
    "with open(f\"../data/_x_test_flat.pickle\", 'wb') as filehandler:\n",
    "    pickle.dump(X_test_flat, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95773047",
   "metadata": {},
   "source": [
    "### test the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04e8dfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f10c0c12610>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_flat = None\n",
    "X_test_flat = None\n",
    "\n",
    "with open(f\"../data/_x_train_flat.pickle\", 'rb') as f:\n",
    "    X_train_flat = np.array(pickle.load(f))\n",
    "\n",
    "with open(f\"../data/_x_test_flat.pickle\", 'rb') as f:\n",
    "    X_test_flat = np.array(pickle.load(f))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1,2,1) \n",
    "ax.imshow(cpm.unflatten(X_train_flat[0]))\n",
    "ax = fig.add_subplot(1,2,2)  \n",
    "ax.imshow(cpm.unflatten(X_test_flat[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea1ae55",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a43b0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.input_dim = (24, 24, 1)\n",
    "ctx.encoder_conv_filters = [32, 64, 64, 64]\n",
    "ctx.encoder_conv_kernel_size = [3,3,3,3]\n",
    "ctx.encoder_conv_strides = [1,2,2,1]\n",
    "ctx.decoder_conv_t_filters = [64,64,32,1]\n",
    "ctx.decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "ctx.decoder_conv_t_strides = [1,2,2,1]\n",
    "ctx.z_dim = 3\n",
    "ctx.n_layers_encoder = len(ctx.encoder_conv_filters)\n",
    "ctx.n_layers_decoder = len(ctx.decoder_conv_t_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5512938d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ece552bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=ctx.input_dim, \n",
    "                      name='encoder_input')\n",
    "\n",
    "x = encoder_input\n",
    "\n",
    "for i in range(ctx.n_layers_encoder):\n",
    "    conv_layer = Conv2D(filters = ctx.encoder_conv_filters[i],\n",
    "                        kernel_size = ctx.encoder_conv_kernel_size[i],\n",
    "                        strides = ctx.encoder_conv_strides[i],\n",
    "                        padding = 'same',\n",
    "                        name = 'encoder_conv_' + str(i))\n",
    "    x = conv_layer(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(rate = 0.25)(x)\n",
    "    \n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "x = Flatten()(x)\n",
    "encoder_output= Dense(ctx.z_dim, name='encoder_output')(x)\n",
    "encoder = Model(encoder_input, encoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52673c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 24, 24, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)      (None, 24, 24, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 2)                 4610      \n",
      "=================================================================\n",
      "Total params: 97,282\n",
      "Trainable params: 97,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ce33e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(ctx.z_dim,), name='decoder_input')\n",
    "\n",
    "x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "for i in range(ctx.n_layers_decoder):\n",
    "    conv_t_layer = Conv2DTranspose(filters = ctx.decoder_conv_t_filters[i],\n",
    "                                   kernel_size = ctx.decoder_conv_t_kernel_size[i],\n",
    "                                   strides = ctx.decoder_conv_t_strides[i],\n",
    "                                   padding = 'same',\n",
    "                                   name = 'decoder_conv_t_' + str(i))\n",
    "    x = conv_t_layer(x)\n",
    "    if i < ctx.n_layers_decoder - 1:\n",
    "        x = LeakyReLU()(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(rate = 0.25)(x)\n",
    "    else:\n",
    "        x = Activation('sigmoid')(x)\n",
    "\n",
    "decoder_output = x\n",
    "decoder = Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8945f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = encoder_input\n",
    "model_output = decoder(encoder_output)\n",
    "\n",
    "model = Model(model_input, model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12f94b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=ctx.learning_rate)\n",
    "model.compile(optimizer=optimizer, loss = r_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "35240004",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat_float = X_train_flat.astype('float32') / 255.\n",
    "X_test_flat_float = X_test_flat.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45cd7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /tmp/ipykernel_679218/3423225362.py:2 r_loss  *\n        return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:2342 mean\n        return math_ops.reduce_mean(x, axis, keepdims)\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:2370 reduce_mean\n        gen_math_ops.mean(\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:5780 mean\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Invalid reduction dimension 3 for input with 3 dimensions. for '{{node r_loss/Mean}} = Mean[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false](r_loss/Square, r_loss/Mean/reduction_indices)' with input shapes: [?,24,24], [3] and with computed input tensors: input[1] = <1 2 3>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_679218/2761069128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlr_sched\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model.fit(X_train_flat_float,\n\u001b[0m\u001b[1;32m     13\u001b[0m           \u001b[0mX_train_flat_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3357\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3277\u001b[0m           expand_composites=True)\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3279\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /tmp/ipykernel_679218/3423225362.py:2 r_loss  *\n        return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:2342 mean\n        return math_ops.reduce_mean(x, axis, keepdims)\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:2370 reduce_mean\n        gen_math_ops.mean(\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:5780 mean\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/tnn1t1s/miniconda3/envs/colorpunx/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Invalid reduction dimension 3 for input with 3 dimensions. for '{{node r_loss/Mean}} = Mean[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false](r_loss/Square, r_loss/Mean/reduction_indices)' with input shapes: [?,24,24], [3] and with computed input tensors: input[1] = <1 2 3>.\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "initial_epoch = 0\n",
    "lr_decay = 1\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=ctx.learning_rate,\n",
    "                               decay_factor=ctx.lr_decay,\n",
    "                               step_size=1)\n",
    "\n",
    "callbacks_list = [lr_sched]\n",
    "\n",
    "model.fit(X_train_flat_float,\n",
    "          X_train_flat_float,\n",
    "          batch_size = ctx.batch_size,\n",
    "          shuffle = True,\n",
    "          epochs = epochs,\n",
    "          initial_epoch = initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb2a5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4b80cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "L = 576\n",
    "# This is our input image\n",
    "input_img = Input(shape=(L,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(L, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "009c137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b0b38c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ea1e7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bdcb96df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000, 576), (1000, 576))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = X_train_flat_float.reshape((len(X_train_flat_float), np.prod(X_train_flat_float.shape[1:])))\n",
    "x_test = X_test_flat_float.reshape((len(X_test_flat_float), np.prod(X_test_flat_float.shape[1:])))\n",
    "(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5df90266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.2033 - val_loss: 0.1978\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1911 - val_loss: 0.1883\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1822 - val_loss: 0.1810\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1752 - val_loss: 0.1751\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1694 - val_loss: 0.1699\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.1646 - val_loss: 0.1656\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1603 - val_loss: 0.1617\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1566 - val_loss: 0.1581\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1531 - val_loss: 0.1548\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1499 - val_loss: 0.1517\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1470 - val_loss: 0.1491\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1442 - val_loss: 0.1464\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1417 - val_loss: 0.1441\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1392 - val_loss: 0.1417\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1369 - val_loss: 0.1396\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1347 - val_loss: 0.1376\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1327 - val_loss: 0.1356\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1306 - val_loss: 0.1337\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1287 - val_loss: 0.1318\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1268 - val_loss: 0.1300\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1249 - val_loss: 0.1281\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.1229 - val_loss: 0.1262\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1210 - val_loss: 0.1242\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1190 - val_loss: 0.1223\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1171 - val_loss: 0.1203\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1150 - val_loss: 0.1183\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1131 - val_loss: 0.1163\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1111 - val_loss: 0.1144\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.1093 - val_loss: 0.1126\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.1076 - val_loss: 0.1111\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1061 - val_loss: 0.1095\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.1047 - val_loss: 0.1082\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.1034 - val_loss: 0.1070\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1021 - val_loss: 0.1059\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1010 - val_loss: 0.1049\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1000 - val_loss: 0.1038\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0990 - val_loss: 0.1029\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0981 - val_loss: 0.1020\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0973 - val_loss: 0.1012\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0965 - val_loss: 0.1005\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0958 - val_loss: 0.0998\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0951 - val_loss: 0.0991\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0945 - val_loss: 0.0985\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0939 - val_loss: 0.0979\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0934 - val_loss: 0.0974\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0928 - val_loss: 0.0969\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0923 - val_loss: 0.0964\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0919 - val_loss: 0.0960\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0915 - val_loss: 0.0956\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0911 - val_loss: 0.0952\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0907 - val_loss: 0.0948\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0904 - val_loss: 0.0945\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0900 - val_loss: 0.0942\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0897 - val_loss: 0.0939\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0895 - val_loss: 0.0937\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0892 - val_loss: 0.0934\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0889 - val_loss: 0.0931\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0887 - val_loss: 0.0929\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0885 - val_loss: 0.0927\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0883 - val_loss: 0.0925\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0881 - val_loss: 0.0923\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0879 - val_loss: 0.0921\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0877 - val_loss: 0.0919\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0875 - val_loss: 0.0918\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0873 - val_loss: 0.0916\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0872 - val_loss: 0.0915\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0870 - val_loss: 0.0913\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0868 - val_loss: 0.0912\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0867 - val_loss: 0.0910\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0866 - val_loss: 0.0909\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0864 - val_loss: 0.0908\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0863 - val_loss: 0.0906\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0862 - val_loss: 0.0905\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0860 - val_loss: 0.0904\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0859 - val_loss: 0.0903\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0858 - val_loss: 0.0902\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0857 - val_loss: 0.0901\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0856 - val_loss: 0.0900\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0855 - val_loss: 0.0898\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0853 - val_loss: 0.0897\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0852 - val_loss: 0.0896\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0851 - val_loss: 0.0896\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0850 - val_loss: 0.0895\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0849 - val_loss: 0.0894\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0848 - val_loss: 0.0893\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0848 - val_loss: 0.0892\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0847 - val_loss: 0.0891\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0846 - val_loss: 0.0890\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0845 - val_loss: 0.0889\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0844 - val_loss: 0.0888\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0843 - val_loss: 0.0888\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0842 - val_loss: 0.0887\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0842 - val_loss: 0.0886\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0841 - val_loss: 0.0885\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0840 - val_loss: 0.0885\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0839 - val_loss: 0.0884\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0839 - val_loss: 0.0883\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0838 - val_loss: 0.0883\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0837 - val_loss: 0.0882\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0837 - val_loss: 0.0881\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0836 - val_loss: 0.0881\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0835 - val_loss: 0.0880\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0835 - val_loss: 0.0880\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0834 - val_loss: 0.0879\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0834 - val_loss: 0.0878\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0833 - val_loss: 0.0878\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0832 - val_loss: 0.0877\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0832 - val_loss: 0.0877\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0831 - val_loss: 0.0876\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0831 - val_loss: 0.0876\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0830 - val_loss: 0.0875\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0830 - val_loss: 0.0875\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0829 - val_loss: 0.0874\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0829 - val_loss: 0.0874\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0828 - val_loss: 0.0873\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0828 - val_loss: 0.0873\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0827 - val_loss: 0.0872\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0827 - val_loss: 0.0872\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0826 - val_loss: 0.0871\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0826 - val_loss: 0.0871\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0825 - val_loss: 0.0871\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0825 - val_loss: 0.0870\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0824 - val_loss: 0.0870\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0824 - val_loss: 0.0870\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0824 - val_loss: 0.0869\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0823 - val_loss: 0.0869\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0823 - val_loss: 0.0868\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0823 - val_loss: 0.0868\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0822 - val_loss: 0.0868\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0822 - val_loss: 0.0867\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0822 - val_loss: 0.0867\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0821 - val_loss: 0.0867\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0821 - val_loss: 0.0866\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0821 - val_loss: 0.0866\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0821 - val_loss: 0.0866\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0820 - val_loss: 0.0866\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0820 - val_loss: 0.0865\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0820 - val_loss: 0.0865\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0819 - val_loss: 0.0865\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0819 - val_loss: 0.0865\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0819 - val_loss: 0.0864\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0819 - val_loss: 0.0864\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0818 - val_loss: 0.0864\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0818 - val_loss: 0.0864\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0818 - val_loss: 0.0863\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0818 - val_loss: 0.0863\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0817 - val_loss: 0.0863\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0817 - val_loss: 0.0863\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0817 - val_loss: 0.0863\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0817 - val_loss: 0.0862\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0817 - val_loss: 0.0862\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0816 - val_loss: 0.0862\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0862\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0816 - val_loss: 0.0862\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0816 - val_loss: 0.0861\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0816 - val_loss: 0.0861\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0815 - val_loss: 0.0861\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0815 - val_loss: 0.0861\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0815 - val_loss: 0.0861\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0815 - val_loss: 0.0860\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0815 - val_loss: 0.0860\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0815 - val_loss: 0.0860\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0814 - val_loss: 0.0860\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0814 - val_loss: 0.0860\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0814 - val_loss: 0.0859\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0814 - val_loss: 0.0859\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0814 - val_loss: 0.0859\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0814 - val_loss: 0.0859\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0813 - val_loss: 0.0859\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0813 - val_loss: 0.0859\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0813 - val_loss: 0.0858\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0813 - val_loss: 0.0858\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0813 - val_loss: 0.0858\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0813 - val_loss: 0.0858\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0813 - val_loss: 0.0858\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0812 - val_loss: 0.0858\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0812 - val_loss: 0.0857\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0812 - val_loss: 0.0857\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0812 - val_loss: 0.0857\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0812 - val_loss: 0.0857\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0812 - val_loss: 0.0857\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0812 - val_loss: 0.0857\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0811 - val_loss: 0.0857\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0811 - val_loss: 0.0856\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0811 - val_loss: 0.0856\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0811 - val_loss: 0.0856\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0811 - val_loss: 0.0856\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0811 - val_loss: 0.0856\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0811 - val_loss: 0.0856\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0811 - val_loss: 0.0855\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0810 - val_loss: 0.0855\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0810 - val_loss: 0.0855\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0810 - val_loss: 0.0855\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0810 - val_loss: 0.0855\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0810 - val_loss: 0.0855\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0810 - val_loss: 0.0855\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0810 - val_loss: 0.0854\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0810 - val_loss: 0.0854\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0809 - val_loss: 0.0854\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0809 - val_loss: 0.0854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1009955340>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ad096bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e015da14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4041994e+01, 2.1154074e+01, 1.7249212e+01, 4.8714056e+00,\n",
       "       5.6191235e+01, 1.4070480e+02, 1.9262086e+03, 2.0370775e+03,\n",
       "       1.0633215e+03, 1.2425227e+03, 2.0326396e+03, 9.8935016e+02,\n",
       "       1.9111764e+03, 9.6963013e+02, 1.2591266e+03, 2.2318088e+03,\n",
       "       8.3491150e+02, 1.8765034e+02, 2.4247536e+02, 1.6163735e+04,\n",
       "       8.0074640e+02, 5.7646594e+02, 1.5890747e+01, 1.6485682e+01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(decoded_imgs[0].reshape(24,24)* 255)[12] * 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "50232868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(24, 24))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(24, 24))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
